{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jTbVYiHBBXks"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 120
    },
    "colab_type": "code",
    "id": "lUcAsY3yBjQK",
    "outputId": "b381b141-29a3-4d73-fdd4-36fcc427331a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s91ScU2ZBXlF"
   },
   "source": [
    "## Задание"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AEAQyvzZBXlG"
   },
   "source": [
    "Реализуйте поиск по [Quora question pairs](https://www.kaggle.com/loopdigga/quora-question-pairs-russian) на нескольких векторных моделях\n",
    "\n",
    "    1. fasttext, модель ruscorpora_none_fasttextskipgram_300_2_2019\n",
    "    2. elmo, модель ruwikiruscorpora_lemmas_elmo_1024_2019\n",
    "    3. bert*, RuBERT - необязательно\n",
    "   \n",
    "Первые две обученные модели можно скачать на сайте [rusvectores](https://rusvectores.org/en/models/).\n",
    "\n",
    "BERT делать необязательно, но если сделаете, 6 за курс у вас автоматом. Модель можно [найти тут](http://docs.deeppavlov.ai/en/master/features/models/bert.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F9NgyT2kBXlH"
   },
   "source": [
    "### __Задача 1__:    \n",
    "Сравните время индексации корпуса для каждой модели "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 421
    },
    "colab_type": "code",
    "id": "O45CXa1LBXlH",
    "outputId": "01b9f885-6b9c-49ec-dae7-43c1d3749f52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Eduard\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Eduard\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "Requirement already satisfied: pymorphy2[fast] in c:\\users\\eduard\\anaconda3\\lib\\site-packages (0.8)\n",
      "Requirement already satisfied: pymorphy2-dicts<3.0,>=2.4 in c:\\users\\eduard\\anaconda3\\lib\\site-packages (from pymorphy2[fast]) (2.4.393442.3710985)\n",
      "Requirement already satisfied: dawg-python>=0.7 in c:\\users\\eduard\\anaconda3\\lib\\site-packages (from pymorphy2[fast]) (0.7.2)\n",
      "Requirement already satisfied: docopt>=0.6 in c:\\users\\eduard\\anaconda3\\lib\\site-packages (from pymorphy2[fast]) (0.6.2)\n",
      "Requirement already satisfied: DAWG>=0.7.3; extra == \"fast\" in c:\\users\\eduard\\anaconda3\\lib\\site-packages (from pymorphy2[fast]) (0.7.8)\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import csv\n",
    "import os\n",
    "from math import log\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from string import punctuation\n",
    "punctuation += '…—'\n",
    "!pip install pymorphy2[fast]\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "import time\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer, TfidfVectorizer\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# ~ global variables\n",
    "pymorphy2_analyzer = MorphAnalyzer()\n",
    "rus_stopwords = stopwords.words('russian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6ywFO4kk-VoQ"
   },
   "outputs": [],
   "source": [
    "# In Google Colab add the following prefix\n",
    "colab_prefix = '/content/drive/My Drive'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6EETOJREBXlK"
   },
   "source": [
    "##### Retrieve queries and docs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "xnPhY2a_BXlL",
    "outputId": "85277386-dc62-41ab-dec6-66519a5cce85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "header: ['', 'question1', 'question2', 'is_duplicate']\n"
     ]
    }
   ],
   "source": [
    "# colab_prefix + \n",
    "with open('quora_question_pairs_rus.csv', 'r', encoding='utf-8') as f:\n",
    "    csv_reader = csv.reader(f)\n",
    "    # skip the header\n",
    "    print('header:', next(csv_reader, None))\n",
    "    queries = []\n",
    "    docs = []\n",
    "    answers = []\n",
    "    for row in csv_reader:\n",
    "        for _, query, doc, answer in csv_reader:\n",
    "            queries.append(query)\n",
    "            docs.append(doc)\n",
    "            answers.append(int(float(answer)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xm7TKRrfBXlN"
   },
   "outputs": [],
   "source": [
    "# функция препроцессинга данных\n",
    "def preprocess_text(text, save_stopwords=True):\n",
    "    lowered_tokens = [word.strip(punctuation) for word in word_tokenize(text.lower()) if word.strip(punctuation)]\n",
    "    if save_stopwords:\n",
    "        return [pymorphy2_analyzer.normal_forms(token)[0] for token in lowered_tokens]\n",
    "    return [pymorphy2_analyzer.normal_forms(token)[0] for token in lowered_tokens if pymorphy2_analyzer.normal_forms(token)[0] not in rus_stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZZ-rW5GzBXlP"
   },
   "outputs": [],
   "source": [
    "# preprocess only first 1000 docs as elmo works too long and bert works even longer...\n",
    "N = 1000\n",
    "tokenized_docs = [preprocess_text(doc) for doc in docs[:N]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gy1L51XzBXlS"
   },
   "source": [
    "##### Fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_gpEyb-2BXlT"
   },
   "outputs": [],
   "source": [
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "\n",
    "model_file = os.path.join(os.getcwd(), '181', 'model.model')\n",
    "\n",
    "fasttext_model = KeyedVectors.load(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a3fcVxofBXlW"
   },
   "outputs": [],
   "source": [
    "def get_fasttext_vector(tokenized_doc, fasttext_model):\n",
    "    # создаем маски для векторов\n",
    "    lemmas_vectors = np.zeros((len(tokenized_doc), fasttext_model.vector_size))\n",
    "    vec = np.zeros((fasttext_model.vector_size,))\n",
    "\n",
    "    # если слово есть в модели, берем его вектор\n",
    "    for idx, lemma in enumerate(tokenized_doc):\n",
    "        if lemma in fasttext_model.vocab:\n",
    "            lemmas_vectors[idx] = fasttext_model.wv[lemma]\n",
    "\n",
    "    return np.mean(lemmas_vectors, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Csm_KSWOBXlZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 190 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fasttext_vectors = np.zeros((len(tokenized_docs), fasttext_model.vector_size))\n",
    "\n",
    "for doc_index, tokenized_doc in enumerate(tokenized_docs):\n",
    "    fasttext_vectors[doc_index] = get_fasttext_vector(tokenized_doc, fasttext_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RqGcIchOBXlb"
   },
   "source": [
    "##### Elmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ppeknWggBXlc"
   },
   "outputs": [],
   "source": [
    "from bilm import Batcher, BidirectionalLanguageModel, weight_layers\n",
    "import tensorflow as tf\n",
    "\n",
    "def load_elmo_embeddings(directory, top=False):\n",
    "    \"\"\"\n",
    "    :param directory: directory with an ELMo model ('model.hdf5', 'options.json' and 'vocab.txt.gz')\n",
    "    :param top: use ony top ELMo layer\n",
    "    :return: ELMo batcher, character id placeholders, op object\n",
    "    \"\"\"\n",
    "    vocab_file = os.path.join(directory, 'vocab.txt')\n",
    "    options_file = os.path.join(directory, 'options.json')\n",
    "    weight_file = os.path.join(directory, 'model.hdf5')\n",
    "\n",
    "    # Create a Batcher to map text to character ids.\n",
    "    batcher = Batcher(vocab_file, 50)\n",
    "\n",
    "    # Input placeholders to the biLM.\n",
    "    sentence_character_ids = tf.placeholder('int32', shape=(None, None, 50))\n",
    "\n",
    "    # Build the biLM graph.\n",
    "    bilm = BidirectionalLanguageModel(options_file, weight_file, max_batch_size=300)\n",
    "\n",
    "    # Get ops to compute the LM embeddings.\n",
    "    sentence_embeddings_op = bilm(sentence_character_ids)\n",
    "\n",
    "    # Get an op to compute ELMo (weighted average of the internal biLM layers)\n",
    "    elmo_sentence_input = weight_layers('input', sentence_embeddings_op, use_top_only=top)\n",
    "    return batcher, sentence_character_ids, elmo_sentence_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tZeUla58BXle"
   },
   "outputs": [],
   "source": [
    "def get_elmo_vectors(sess, texts, batcher, sentence_character_ids, elmo_sentence_input):\n",
    "    \"\"\"\n",
    "    :param sess: TensorFlow session\n",
    "    :param texts: list of sentences (lists of words)\n",
    "    :param batcher: ELMo batcher object\n",
    "    :param sentence_character_ids: ELMo character id placeholders\n",
    "    :param elmo_sentence_input: ELMo op object\n",
    "    :return: embedding matrix for all sentences (max word count by vector size)\n",
    "    \"\"\"\n",
    "\n",
    "    # Create batches of data.\n",
    "    sentence_ids = batcher.batch_sentences(texts)\n",
    "    print('Sentences in this batch:', len(texts), file=sys.stderr)\n",
    "\n",
    "    # Compute ELMo representations.\n",
    "    elmo_sentence_input_ = sess.run(elmo_sentence_input['weighted_op'],\n",
    "                                    feed_dict={sentence_character_ids: sentence_ids})\n",
    "\n",
    "    return elmo_sentence_input_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Aq7nnUMvBXlh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Eduard\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Eduard\\Desktop\\Projects\\infosearch\\3 Semantics\\bilm\\model.py:522: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From C:\\Users\\Eduard\\Desktop\\Projects\\infosearch\\3 Semantics\\bilm\\model.py:567: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From C:\\Users\\Eduard\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py:626: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "# переделать на os.path.join() с подпапкой\n",
    "batcher, sentence_character_ids, elmo_sentence_input = load_elmo_embeddings(os.path.join(os.getcwd(), '196'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YdCJ5a9RBXlm"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sentences in this batch: 300\n",
      "Sentences in this batch: 300\n",
      "Sentences in this batch: 300\n",
      "Sentences in this batch: 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#         embedding_op computes the LM embeddings and is shape\n",
    "#             (None, 3, None, 1024) (c) docs\n",
    "elmo_vector_size = 1024\n",
    "elmo_vectors = np.zeros((len(tokenized_docs), elmo_vector_size))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    batch_size = 300\n",
    "    for i in range(0, len(tokenized_docs), batch_size):\n",
    "        elmo_vectors[i:i + batch_size] = np.mean(get_elmo_vectors(\n",
    "            sess, tokenized_docs[i:i + batch_size], batcher, sentence_character_ids, elmo_sentence_input), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E8Ivx33WBXlt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor shape: (1000, 1024)\n"
     ]
    }
   ],
   "source": [
    "print('Tensor shape:', elmo_vectors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SKPdvxQ9BXlv"
   },
   "source": [
    "##### Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 923
    },
    "colab_type": "code",
    "id": "Ii1pwQQkBXlw",
    "outputId": "398ebfd0-478b-4858-f139-11ee347b5f56",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras_bert\n",
      "  Downloading https://files.pythonhosted.org/packages/ae/ac/a8488c0cde97c6639f5dfd788973853a01e0cb49f6634c6d2a2780f71413/keras-bert-0.79.0.tar.gz\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras_bert) (1.16.5)\n",
      "Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from keras_bert) (2.2.5)\n",
      "Collecting keras-transformer>=0.30.0 (from keras_bert)\n",
      "  Downloading https://files.pythonhosted.org/packages/0a/57/496b1eab888171b0801a0a44d3245a7874b8d1cc04c1fbfdbb5e3327fc7a/keras-transformer-0.31.0.tar.gz\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_bert) (1.1.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras->keras_bert) (3.13)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_bert) (1.3.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_bert) (1.0.8)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_bert) (1.12.0)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras->keras_bert) (2.8.0)\n",
      "Collecting keras-pos-embd>=0.10.0 (from keras-transformer>=0.30.0->keras_bert)\n",
      "  Downloading https://files.pythonhosted.org/packages/09/70/b63ed8fc660da2bb6ae29b9895401c628da5740c048c190b5d7107cadd02/keras-pos-embd-0.11.0.tar.gz\n",
      "Collecting keras-multi-head>=0.22.0 (from keras-transformer>=0.30.0->keras_bert)\n",
      "  Downloading https://files.pythonhosted.org/packages/40/3e/d0a64bb2ac5217928effe4507c26bbd19b86145d16a1948bc2d4f4c6338a/keras-multi-head-0.22.0.tar.gz\n",
      "Collecting keras-layer-normalization>=0.12.0 (from keras-transformer>=0.30.0->keras_bert)\n",
      "  Downloading https://files.pythonhosted.org/packages/ea/f3/a92ce51219280eea003911722046db17eaebf5f26679a73887a5c357abe4/keras-layer-normalization-0.13.0.tar.gz\n",
      "Collecting keras-position-wise-feed-forward>=0.5.0 (from keras-transformer>=0.30.0->keras_bert)\n",
      "  Downloading https://files.pythonhosted.org/packages/e3/59/f0faa1037c033059e7e9e7758e6c23b4d1c0772cd48de14c4b6fd4033ad5/keras-position-wise-feed-forward-0.6.0.tar.gz\n",
      "Collecting keras-embed-sim>=0.7.0 (from keras-transformer>=0.30.0->keras_bert)\n",
      "  Downloading https://files.pythonhosted.org/packages/bc/20/735fd53f6896e2af63af47e212601c1b8a7a80d00b6126c388c9d1233892/keras-embed-sim-0.7.0.tar.gz\n",
      "Collecting keras-self-attention==0.41.0 (from keras-multi-head>=0.22.0->keras-transformer>=0.30.0->keras_bert)\n",
      "  Downloading https://files.pythonhosted.org/packages/1b/1c/01599219bef7266fa43b3316e4f55bcb487734d3bafdc60ffd564f3cfe29/keras-self-attention-0.41.0.tar.gz\n",
      "Building wheels for collected packages: keras-bert, keras-transformer, keras-pos-embd, keras-multi-head, keras-layer-normalization, keras-position-wise-feed-forward, keras-embed-sim, keras-self-attention\n",
      "  Building wheel for keras-bert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for keras-bert: filename=keras_bert-0.79.0-cp36-none-any.whl size=37973 sha256=7e9354d5f51f61d835abfe15ca9296e96f0d78fcf72f2db67ca2db87528519ef\n",
      "  Stored in directory: /root/.cache/pip/wheels/1e/3d/f6/5785f07131994c4af150afc4d09470c811af541f79e266e50e\n",
      "  Building wheel for keras-transformer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for keras-transformer: filename=keras_transformer-0.31.0-cp36-none-any.whl size=13385 sha256=f44a9b85a45838d2b370dad9ad6fb9df83bc0e79500bde0b7c09dba98a7bd398\n",
      "  Stored in directory: /root/.cache/pip/wheels/a3/c5/9a/5a5130240be614a7a6fa786765d7692ae97f82601e2161bb56\n",
      "  Building wheel for keras-pos-embd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for keras-pos-embd: filename=keras_pos_embd-0.11.0-cp36-none-any.whl size=7553 sha256=0e488c52f392f5c0a897e0691804755c3cf6b8479df6c90e54702fb8fd5f8225\n",
      "  Stored in directory: /root/.cache/pip/wheels/5b/a1/a0/ce6b1d49ba1a9a76f592e70cf297b05c96bc9f418146761032\n",
      "  Building wheel for keras-multi-head (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for keras-multi-head: filename=keras_multi_head-0.22.0-cp36-none-any.whl size=15371 sha256=d8ec1ec5454ee891f8f3844a6ddb7ae1632d74dd6595ae933b14fc02abc0dc64\n",
      "  Stored in directory: /root/.cache/pip/wheels/bb/df/3f/81b36f41b66e6a9cd69224c70a737de2bb6b2f7feb3272c25e\n",
      "  Building wheel for keras-layer-normalization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for keras-layer-normalization: filename=keras_layer_normalization-0.13.0-cp36-none-any.whl size=5209 sha256=8f9f17447f8be20e277f54875036ca0016c328cb626d78bfa0b3180cb25d8b4f\n",
      "  Stored in directory: /root/.cache/pip/wheels/50/2b/71/d1d06f71d78c46a9912dc89a5bb46f357cf64fa05883fadc64\n",
      "  Building wheel for keras-position-wise-feed-forward (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for keras-position-wise-feed-forward: filename=keras_position_wise_feed_forward-0.6.0-cp36-none-any.whl size=5624 sha256=c8910e941d8adeb2ff3c5b321ab37ed86120477a7ea17c421242143392df56ef\n",
      "  Stored in directory: /root/.cache/pip/wheels/39/e2/e2/3514fef126a00574b13bc0b9e23891800158df3a3c19c96e3b\n",
      "  Building wheel for keras-embed-sim (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for keras-embed-sim: filename=keras_embed_sim-0.7.0-cp36-none-any.whl size=4676 sha256=acc28ec4555707ca41187c3533d122f78bc5963c18d7ccc9b330be8fea9aed7d\n",
      "  Stored in directory: /root/.cache/pip/wheels/d1/bc/b1/b0c45cee4ca2e6c86586b0218ffafe7f0703c6d07fdf049866\n",
      "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for keras-self-attention: filename=keras_self_attention-0.41.0-cp36-none-any.whl size=17290 sha256=4d2d5f70e5649682f6711621b587b27e5552e6a9b0835b8eb913fb7ae079bcbd\n",
      "  Stored in directory: /root/.cache/pip/wheels/cc/dc/17/84258b27a04cd38ac91998abe148203720ca696186635db694\n",
      "Successfully built keras-bert keras-transformer keras-pos-embd keras-multi-head keras-layer-normalization keras-position-wise-feed-forward keras-embed-sim keras-self-attention\n",
      "Installing collected packages: keras-pos-embd, keras-self-attention, keras-multi-head, keras-layer-normalization, keras-position-wise-feed-forward, keras-embed-sim, keras-transformer, keras-bert\n",
      "Successfully installed keras-bert-0.79.0 keras-embed-sim-0.7.0 keras-layer-normalization-0.13.0 keras-multi-head-0.22.0 keras-pos-embd-0.11.0 keras-position-wise-feed-forward-0.6.0 keras-self-attention-0.41.0 keras-transformer-0.31.0\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "!pip install keras_bert\n",
    "from keras_bert import load_vocabulary, load_trained_model_from_checkpoint, Tokenizer, get_checkpoint_paths\n",
    "from keras_bert.layers import MaskedGlobalMaxPool1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AtvrOMQ5BXlz"
   },
   "outputs": [],
   "source": [
    "model_path = '/content/drive/My Drive/bert'\n",
    "paths = get_checkpoint_paths(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7hiAEizMBXl1"
   },
   "outputs": [],
   "source": [
    "seq_len = 50\n",
    "bert_model = load_trained_model_from_checkpoint(config_file=paths.config, checkpoint_file=paths.checkpoint, seq_len=seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kaa4DLt5BXl6"
   },
   "outputs": [],
   "source": [
    "pool_layer = MaskedGlobalMaxPool1D(name='Pooling')(bert_model.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "55vVDZnLDZ5p"
   },
   "outputs": [],
   "source": [
    "bert_model = keras.models.Model(inputs=bert_model.inputs, outputs=pool_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "swyo_1HqBXl8"
   },
   "outputs": [],
   "source": [
    "token_dict = load_vocabulary(paths.vocab)\n",
    "tokenizer = Tokenizer(token_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EnDAuy1bB_dS"
   },
   "outputs": [],
   "source": [
    "def get_bert_vector(doc, bert_model, token_dict, seq_len):\n",
    "    tokenized_doc = tokenizer.tokenize(doc)[:seq_len]\n",
    "    segments = [0] * seq_len\n",
    "    indices = [token_dict[elem] for elem in tokenized_doc]\n",
    "    indices += [0] * (seq_len - len(indices))\n",
    "    return bert_model.predict([np.array([indices]), np.array([segments])])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "nW9jKXR9BXl-",
    "outputId": "a8371f63-32dd-4af1-eed4-3deb03909b61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.3 s, sys: 1.7 s, total: 20 s\n",
      "Wall time: 22.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bert_vector_size = 768\n",
    "bert_vectors = np.zeros((len(tokenized_docs), bert_vector_size))\n",
    "\n",
    "for i, tokenized_doc in enumerate(tokenized_docs):\n",
    "    bert_vectors[i] = get_bert_vector(' '.join(tokenized_doc), bert_model, token_dict, seq_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xi4eTAQPBXmA"
   },
   "source": [
    "### __Задача 2__:    \n",
    "Выведите качество поиска для каждой модели +  BM25 для сравнения\n",
    "\n",
    "Качество оцениваем так же, как в прошлом задании:\n",
    "    - если в топ-5 результатов выдачи попал хоть один релевантный документ, выдача точная\n",
    "    - если в топ-5 нет ни одного релеватного документа, выдача получает 0\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BeeOqWIBBXmB"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y-oNB-BvBXmE"
   },
   "outputs": [],
   "source": [
    "def get_most_probable_docs(doc_vector, docs_matrix):\n",
    "    cosine_values = cosine_similarity(docs_matrix, doc_vector.reshape(1, -1)).reshape(docs_matrix.shape[0])\n",
    "    return [docs[doc_id] for doc_id, _ in sorted(list(\n",
    "        enumerate(cosine_values)), key=lambda elem: elem[1], reverse=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t-2sd8BKBXmK"
   },
   "outputs": [],
   "source": [
    "def search_fasttext(query, fasttext_model, fasttext_vectors):\n",
    "    return get_most_probable_docs(get_fasttext_vector(preprocess_text(query), fasttext_model), fasttext_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i6TpgPZzBXmN"
   },
   "outputs": [],
   "source": [
    "def search_elmo(query, elmo_vectors, sess, batcher, sentence_character_ids, elmo_sentence_input):\n",
    "    tokenized_query = preprocess_text(query)\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        elmo_vector = np.mean(get_elmo_vectors(\n",
    "            sess, [tokenized_query], batcher, sentence_character_ids, elmo_sentence_input), axis=1)[0]\n",
    "    return get_most_probable_docs(elmo_vector, elmo_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pkfbK16WBXmO"
   },
   "outputs": [],
   "source": [
    "def search_bert(query, bert_vectors, bert_model, token_dict, seq_len):\n",
    "    bert_vector = get_bert_vector(query, bert_model, token_dict, seq_len)\n",
    "    return get_most_probable_docs(bert_vector, bert_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w9DFzUCWBXmQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 - почему я чувствую, что я взволнован чем-то, когда мне нечего волноваться\n",
      "2 - почему люди ненавидят шарух хана и почему люди чувствуют, что он не индийский\n",
      "3 - парень, с которым я встречаюсь, никогда не пишет меня, и я чувствую, что он не заботится обо мне, но когда я вижу его, он показывает мне, что он любит меня и хочет меня, почему я так себя чувствую\n",
      "4 - почему большинство парней в Индии становятся настолько отчаянными, что они не знают, что девочки не всегда ищут отношения, это повредит парням, чтобы стать нашим другом первым\n",
      "5 - почему я хочу остаться одиноким всю свою жизнь после моего распада, почему я чувствую, что я закончил эту серьезную связь\n"
     ]
    }
   ],
   "source": [
    "results = search_fasttext('почему я чувствую, что я взволнован чем-то', fasttext_model, fasttext_vectors)\n",
    "print('\\n'.join([f'{i + 1} - {elem}' for i, elem in enumerate(results[:5])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pt_1kd3yBXmS"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sentences in this batch: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 - почему я чувствую, что я взволнован чем-то, когда мне нечего волноваться\n",
      "2 - парень, с которым я встречаюсь, никогда не пишет меня, и я чувствую, что он не заботится обо мне, но когда я вижу его, он показывает мне, что он любит меня и хочет меня, почему я так себя чувствую\n",
      "3 - как я могу избавиться от чувства, что мой супруг обманывает меня?\n",
      "4 - почему я хочу остаться одиноким всю свою жизнь после моего распада, почему я чувствую, что я закончил эту серьезную связь\n",
      "5 - как мне пережить кого-то, кого я любил сейчас, когда мы расстались в прошлом году, и я все еще скучаю по ней\n"
     ]
    }
   ],
   "source": [
    "results = search_elmo('почему я чувствую, что я взволнован чем-то', elmo_vectors, sess, batcher, sentence_character_ids, elmo_sentence_input)\n",
    "print('\\n'.join([f'{i + 1} - {elem}' for i, elem in enumerate(results[:5])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 100
    },
    "colab_type": "code",
    "id": "c3w1LnRcBXmU",
    "outputId": "41342956-cf86-4367-e4ca-65f569713e73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 - почему я чувствую, что я взволнован чем-то, когда мне нечего волноваться\n",
      "2 - почему я не хочу разговаривать с кем-то\n",
      "3 - что я могу сделать, чтобы не ревновать кого-то\n",
      "4 - как я перестаю быть зависимым от кого-то\n",
      "5 - как я должен перестать думать о ком-то\n"
     ]
    }
   ],
   "source": [
    "results = search_bert('почему я чувствую, что я взволнован чем-то', bert_vectors, bert_model, token_dict, seq_len)\n",
    "print('\\n'.join([f'{i + 1} - {elem}' for i, elem in enumerate(results[:5])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jgwC7mv4C5tc"
   },
   "outputs": [],
   "source": [
    "def count_bert_precision(num_of_docs=1000):\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    for query, doc, answer in zip(queries[:num_of_docs], docs[:num_of_docs], answers[:num_of_docs]):\n",
    "        results = search_bert(query, bert_vectors, bert_model, token_dict, seq_len)\n",
    "        if doc in results[:5]:\n",
    "            if answer:\n",
    "                tp += 1\n",
    "            else:\n",
    "                fp += 1\n",
    "    return tp / (tp + fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "Ju1M1zZ6EKPy",
    "outputId": "e4cb8dfa-5e66-44ab-9ed8-396d23e42cc9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49643705463182897"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_precision = count_bert_precision()\n",
    "bert_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ercCNgA3EYuV"
   },
   "outputs": [],
   "source": [
    "def count_elmo_precision(num_of_docs=1000):\n",
    "    tokenized_queries = [preprocess_text(query) for query in queries[:num_of_docs]]\n",
    "    elmo_query_vectors = np.zeros((num_of_docs, elmo_vector_size))\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        batch_size = 300\n",
    "        for i in range(0, num_of_docs, batch_size):\n",
    "            elmo_query_vectors[i:i + batch_size] = np.mean(get_elmo_vectors(\n",
    "                sess, tokenized_queries[i:i + batch_size], batcher, sentence_character_ids, elmo_sentence_input), axis=1)\n",
    "\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    for elmo_query_vector, doc, answer in zip(elmo_query_vectors, docs[:num_of_docs], answers[:num_of_docs]):\n",
    "        results = get_most_probable_docs(elmo_query_vector, elmo_vectors)\n",
    "        if doc in results[:5]:\n",
    "            if answer:\n",
    "                tp += 1\n",
    "            else:\n",
    "                fp += 1\n",
    "    return tp / (tp + fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pCPFjxM7EbQj"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sentences in this batch: 300\n",
      "Sentences in this batch: 300\n",
      "Sentences in this batch: 300\n",
      "Sentences in this batch: 100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.48462664714494874"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elmo_precision = count_elmo_precision()\n",
    "elmo_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dEJEMw9bEdtp"
   },
   "outputs": [],
   "source": [
    "def count_fasttext_precision(num_of_docs=1000):\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    for query, doc, answer in zip(queries[:num_of_docs], docs[:num_of_docs], answers[:num_of_docs]):\n",
    "        results = search_fasttext(query, fasttext_model, fasttext_vectors)\n",
    "        if doc in results[:5]:\n",
    "            if answer:\n",
    "                tp += 1\n",
    "            else:\n",
    "                fp += 1\n",
    "    return tp / (tp + fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4778625954198473"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fasttext_precision = count_fasttext_precision()\n",
    "fasttext_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# см. предыдущую домашнюю работу (b=1, num_of_docs=1000)\n",
    "bm25_precision = 0.5386029411764706"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects = ax.bar(range(4), [fasttext_precision, elmo_precision, bert_precision, bm25_precision], 0.5, color='g')\n",
    "ax.set_ylabel('Precision')\n",
    "ax.set_xticks(np.add(range(4), 1/50))\n",
    "ax.set_xticklabels((['fasttext_precision', 'elmo_precision', 'bert_precision', 'bm25_precision']))\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "sem3_semantics.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
